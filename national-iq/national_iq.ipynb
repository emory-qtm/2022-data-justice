{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Dismantling Statistical Proofs of Evolutionary Theories of Intelligence </h1>\n",
    "\n",
    "This notebook was written by Michal Arbilly and Mack Hutsell based on a 2010 paper by Jelte Wilcherts, Denny Borsboom, and Conor Dolan titled [Why national IQs do not support evolutionary theories of intelligence](https://www.sciencedirect.com/science/article/abs/pii/S0191886909002475).\n",
    "\n",
    "<h3> Table of Contents </h3>\n",
    "\n",
    "**(Complete)**\n",
    "\n",
    "1. [Learning Goals](#Learning_goals)\n",
    "2. [Background](#Background)\n",
    "    1. [Introduction to Intelligence Quotients (IQs)](#IQ_bg)\n",
    "    2. [Summaries of Papers we Will Debunk](#Recent_IQ_Studies)\n",
    "        1. [Issues with the Methodologies of Targeted Papers (Optional)](#paper_methodology_errors)\n",
    "    3. [Correlation and Confounding](#c_and_c)\n",
    "        1. [Basic Correlation](#corr_basic)\n",
    "        2. [Basic Confounding](#conf_basic)\n",
    "        3. [Correlation and Confounding Conclusion](#corr_and_conf_conc)        \n",
    "        \n",
    "**(Incomplete)**\n",
    "\n",
    "3. [Analysis](#Analysis)\n",
    "    1. [Datasets](#datasets)\n",
    "    2. [Applying PCA](#pca)\n",
    "4. [Evaluation](#Evaluation)\n",
    "5. [Conclusion](#Conclusion)\n",
    "\n",
    "**(Partially Complete)**\n",
    "\n",
    "6. [Sources](#Sources)\n",
    "\n",
    "<h2> Learning Goals <a name=\"Learning_goals\"></a></h2>\n",
    "\n",
    "1. Gain a basic understanding of statistical methods and pitfalls\n",
    "\n",
    "    - What is correlation?\n",
    "    \n",
    "    - What is confounding?\n",
    "\n",
    "    - How can bias enter statistics-based research?\n",
    "    \n",
    "\n",
    "<h2> Background <a name=\"Background\"></a></h2>\n",
    "\n",
    "<h3> 1. The Study of IQ <a name=\"IQ_bg\"></a></h3>\n",
    "\n",
    "An Intelligence Quotient, or IQ, is a score resulting from a test designed to assess human intelligence. Over the past 100 years, it has been one of the most controversial and widely studied psychometrics. IQ scores have been used as a basis for eugenics programs, both in the US and Nazi Germany, and they are still used by the US army to determine who to accept/deny. The SAT, even, was originally an IQ test for high schoolers that was developed in part by a eugenicist, Carl Brigham, who believed it would prove white racial superiority.\n",
    "\n",
    "<h3> 2. Recent Applications of IQ-based Statistical Science <a name=\"Recent_IQ_Studies\"></a></h3>\n",
    "\n",
    "Our notebook today is based on a paper that was written specifically to **debunk** several previous papers, Kanazawa 2008, Templer 2008, and Templer and Arikawa 2006.\n",
    "\n",
    "These papers, in summary, claimed that they \"found empirical support for evolutionary theories of race differences in intelligence by **correlating estimates of national IQ with reproductive strategies, temperature, and geographic distance from Africa**.\"\n",
    "\n",
    "Each of these three correlations they claimed to have found were based on corresponding **evolutionary theories of intelligence**:\n",
    "\n",
    "1. \"higher general intelligence evolved to meet the challenge of surviving in colder and more demanding climates\" (Lynn, 1991, 2006)\n",
    "\n",
    "2. \"general intelligence evolved in response to new environmental challenges that didn't exist in the EEA\" (EEA, in this context, refers to Sub-Saharan Africa in the late Pleistocene, around when humans developed) (Kanazawa, 2004)\n",
    "\n",
    "3. \"the three major human races (i.e., Whites, Blacks, and Asians) differ in levels of intelligence because of different evolved reproductive strategies.\" (Rushton, 2000)\n",
    "\n",
    "Kanazawa (2008) focused on theories 1 and 2.\n",
    "\n",
    "Templer (2008) focused on theory 3\n",
    "\n",
    "Templer and Arikawa (2006) focused on theory 1.\n",
    "\n",
    "Wicherts, Borsboom, and Dolan, found errors in the **methodologies** of each of the above papers. While these errors are interesting, they **aren't essential** to what we'll be learning in the notebook today. They've been summarized below for those interested.\n",
    "\n",
    "> **Optional**\n",
    "> <h4> Some Basic Issues with the Methodologies of the Papers <a name=\"paper_methodology_errors\"></a> </h4>\n",
    ">\n",
    "> **Need to re-phrase the below issues**\n",
    ">\n",
    "> The following noted issues constitute a **Part 1** of the paper this notebook was based on.\n",
    "> \n",
    "> 1. Authors ignore whether IQ reflects intelligence / whether race is a measurable construct. Assume that nations may differ in terms of racially dominant groups, that national IQ reflects general intelligence.\n",
    "> \n",
    "> 2. They base their hypotheses on the \"Out of Africa\" hypothesis. Their evolutionary hypotheses are based on events that took place 60-100 thousand years ago but the data they use to test the hypotheses were gathered in the 20th century.\n",
    "> \n",
    "> 3. Basically temperature was different a long time ago from now.\n",
    "> \n",
    "> 4. First, Kanazawa operationalized geographic distance using Pythagoras’ first theorem (a2 + b2 = c2). However, Pythagoras’ theorem applies to Euclidian space, not to the surface of a sphere. Second, even if these calculations were accurate, distances as traveled on foot do not in general correspond to distances ‘‘as the crow flies” (Kanazawa 2008, p. 102). Third, it is not obvious that locations farther removed from the African Savannah are geographically and ecologically more dissimilar than locations closer to the African Savannah. It is also noteworthy that given the time span of evolutionary theories, it is hardly useful to speak of environmental effects as if these were fixed at a certain geographical location.\n",
    "> \n",
    "> 5. People migrate, and instead of using countries w/ mostly indigenous inhabitants, they even used countries like Australia and the United States. Bad.\n",
    "> \n",
    "> 6. the mean IQ of Dutch citizens, as computed in 1982 is not even a reasonable estimate of the mean Dutch IQ in 1952, so how could it be constant across thousands of years. Flynn effect exists (IQ increases every decade or so)\n",
    "\n",
    "Today we will be concerned with **errors in the statistical analysis** performed by each of the papers.\n",
    "\n",
    "The basis of their refutation of the above papers' statistical analyses was in establishing that \"national IQs are **strongly confounded** with the current developmental status of countries\".\n",
    "\n",
    "It is important to note that there are many **scientific questions** related to this topic that we will not be addressing in this notebook. But they are good to keep in mind as we proceed.\n",
    "\n",
    "For example: is IQ a good representation of human intelligence? Would national IQ's reflect general intelligence of a country? \n",
    "\n",
    "And, as Wilcherts, et. al note: \"our criticisms concern the evidential force of data on national IQs with respect to evolutionary theories of intelligence, rather than the truth of these evolutionary theories per se\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Before** we move on to understanding why the papers' statistical analyses were flawed, let's briefly cover **correlation and confounding**. Both will be important later on.\n",
    "\n",
    "<h3> 3. Correlation and Confounding <a name=\"c_and_c\"></a></h3>\n",
    "\n",
    "Definitions:\n",
    "\n",
    "**Correlation:** interdependence of variable quantities. (more simply: a connection between two or more things)\n",
    "\n",
    "**Confounder:** a variable that influences both the dependent variable and independent variable, causing a spurious association. (more simply: something that influences multiple things in such a way that those things seem related to each other)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Correlation <a name=\"corr_basic\"></a></h4>\n",
    "\n",
    "**Note:** if you're familiar with Pearson's Correlation Coefficient and its calculation, feel free to move on to [Confounding](#conf_basic)\n",
    "\n",
    "Let's imagine a situation which might call for **basic correlation**.\n",
    "\n",
    "A grocery store sells both peanut butter, jelly, corn, and milk. They notice that in the last three days, their sales for each item are:\n",
    "\n",
    ">| Sales | PB     | J     | Corn | Milk\n",
    ">| :------------- | :---------- | :----------- | :----------- | :----------- |\n",
    ">|  Mon | 2 | 2 | 4 | 8 |\n",
    ">| Tues | 3 | 3 | 3 | 10 |\n",
    ">| Wed | 4 | 4 | 2 | 8 |\n",
    "\n",
    "Just from observing the chart, we can tell that the sales PB and J **seem** to be positively related. As in, when peanut butter sales are higher, so are jelly sales.\n",
    "\n",
    "Similarly, PB and corn sales seem to be negatively related, while PB and Milk sales seem to not be related at all.\n",
    "\n",
    "***The question is***: how can we **mathematically establish** these relations, or correlations?\n",
    "\n",
    "There are different ways to mathematically establish a correlation, but a very common method is to use **Pearson's Correlation Coefficient**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Pearson_Correlation_Formula.gif\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:**\n",
    "\n",
    "**n** - the number of values that we have (we have 3 — one for Mon, Tues, and Wed)\n",
    "\n",
    "**x** - the first variable that we inspect (in our case, it will be peanut butter)\n",
    "\n",
    "**y** - the second variable that we inspect (in our case, this will be jelly, then corn, then milk)\n",
    "\n",
    "For this formula, a values range from -1 to 1. \n",
    "\n",
    "A 1 represents **strong positive** correlation, while a -1 represents a **strong negative** correlation and a 0 represents a **neutral** correlation (or no correlation). But note that the correlation coefficients can end up anywhere between these!\n",
    "\n",
    "Let's put our data into python so that we can calculate the correlation coefficient.\n",
    "\n",
    "If you run the following block of code, it will initialize our variables as well as print out our data in its dataframe form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Mon</th>\n",
       "      <th>Tues</th>\n",
       "      <th>Wed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PB</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>J</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Corn</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Milk</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Product  Mon  Tues  Wed\n",
       "0      PB    2     3    4\n",
       "1       J    2     3    4\n",
       "2    Corn    4     3    2\n",
       "3    Milk    8    10    8"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "# Put our data into a list of lists\n",
    "data = [['PB', 2, 3, 4], ['J', 2, 3, 4], ['Corn', 4, 3, 2], ['Milk', 8, 10, 8]]\n",
    " \n",
    "# Create a pandas DataFrame\n",
    "df = pd.DataFrame(data, columns = ['Product', 'Mon', 'Tues', 'Wed'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's calculate the correlation coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson Correlation Coefficient Between 'PB' and 'J': 1.0\n"
     ]
    }
   ],
   "source": [
    "def calc_pearson_coefficient(x, y):\n",
    "    # Calculating components n, sum_x, sum_x_squared, sum_y, sum_y_squared, and sum_xy\n",
    "    data_value_col_names = df.columns[1:] # We get all the column names in our dataframe, except we ignore the first column\n",
    "                                          # Because the \"Product\" column doesn't have any important data value for our correlation\n",
    "    n = len(data_value_col_names) # Get number of data values\n",
    "    \n",
    "    # Get just the row of our dataframe that corresponds to Product == x (on our first call, x is \"PB\")\n",
    "    x_row = df.loc[df['Product'] == x]\n",
    "    sum_x = 0\n",
    "    sum_x_squared = 0\n",
    "    y_row = df.loc[df['Product'] == y]\n",
    "    sum_y = 0\n",
    "    sum_y_squared = 0\n",
    "    sum_xy = 0\n",
    "    # Iterate through each of the days of the week we have data values for and calculate our components\n",
    "    for j in data_value_col_names:\n",
    "        x_val = int(x_row[j])\n",
    "        y_val = int(y_row[j])        \n",
    "        sum_x += x_val\n",
    "        sum_x_squared += x_val ** 2\n",
    "        sum_y += y_val\n",
    "        sum_y_squared += y_val ** 2\n",
    "        sum_xy += x_val * y_val\n",
    "\n",
    "    # Now we have all of our components and we can calculate the coefficient\n",
    "    numerator = n * (sum_xy) - (sum_x) * (sum_y)\n",
    "    denominator = math.sqrt( ( (n * float(sum_x_squared) - (sum_x) ** 2) * ( (n * sum_y_squared) - (sum_y) ** 2 ) ) )\n",
    "    if denominator == 0:\n",
    "        print(\"Denominator was 0! Correlation Coefficient is undefined\")\n",
    "        return \"Not Defined\"\n",
    "    r = float(numerator) / denominator\n",
    "    return r\n",
    "# Calculate and print the pearson correlation coefficient between \"PB\" and \"J\"\n",
    "print(\"Pearson Correlation Coefficient Between 'PB' and 'J': {}\".format(calc_pearson_coefficient(\"PB\", \"J\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've proven, from a **statistical** standpoint, that PB and J are correlated!\n",
    "\n",
    "Great, now let's check out how Corn and Milk relate to PB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson Correlation Coefficient Between 'PB' and 'Corn': -1.0\n",
      "Pearson Correlation Coefficient Between 'PB' and 'Milk': 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Pearson Correlation Coefficient Between 'PB' and 'Corn': {}\".format(calc_pearson_coefficient(\"PB\", \"Corn\")))\n",
    "print(\"Pearson Correlation Coefficient Between 'PB' and 'Milk': {}\".format(calc_pearson_coefficient(\"PB\", \"Milk\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results also **align** with our previous intuitions.\n",
    "\n",
    "Try playing around with the data and inspecting how it changes the correlation coefficient. \n",
    "\n",
    "Note that if the values for a variable never change, the denominator of the formula will be 0, resulting in an **undefined** correlation coefficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Confounding <a name=\"conf_basic\"></a></h4>\n",
    "\n",
    "As mentioned earlier, a confounder is something that influences multiple things in such a way that they seem related, or connected.\n",
    "\n",
    "To see how a confounder can affect a statistical analysis, let's take the same data that we were just working with:\n",
    "\n",
    ">| Sales | PB     | J     | Corn | Milk\n",
    ">| :------------- | :---------- | :----------- | :----------- | :----------- |\n",
    ">|  Mon | 2 | 2 | 4 | 8 |\n",
    ">| Tues | 3 | 3 | 3 | 10 |\n",
    ">| Wed | 4 | 4 | 2 | 8 |\n",
    "\n",
    "Here, our intuition from observing the chart, as well as our statistical analysis told us that PB and J were highly correlated.\n",
    "\n",
    "**But** let's imagine that **another set of variables** exist: number of advertisements a day for a certain product.\n",
    "\n",
    ">| Advertisements | PB     | J     | Corn | Milk\n",
    ">| :------------- | :---------- | :----------- | :----------- | :----------- |\n",
    ">|  Mon | 2 | 2 | 4 | 8 |\n",
    ">| Tues | 3 | 3 | 3 | 10 |\n",
    ">| Wed | 4 | 4 | 2 | 8 |\n",
    "\n",
    "Now that we know this data exists, **maybe it's not** that PB and J were correlated that caused them to be purchased at the same rates, maybe it's because they had the **same number of advertisements** each day!\n",
    "\n",
    "Confounders can come in **many** types and magnitudes of influence. While this example is contrived, it demonstrates something **important**: sometimes a dataset doesn't tell the whole story."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Correlation and Confounding Conclusion <a name=\"corr_and_conf_conc\"></a></h4>\n",
    "\n",
    "Because of confounders, data can easily be manipulated to show **arbitrary and ridiculous** correlations. For example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"bad_correlation.jpeg\">\n",
    "\n",
    "Source: https://www.tylervigen.com/spurious-correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this correlation is clearly caused by multiple confounders, the more dangerous correlations are those that **seem** like they could be true, or even worse those that we **want** to be true.\n",
    "\n",
    "This is a common way for a researcher's bias to end up impacting their research."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Analysis <a name=\"Analysis\"></a></h2>\n",
    "\n",
    "Now that we have a basic understanding of correlation and confounding, let's start to take a look at how Wicherts, et. al refute the statistical approaches taken by Kanazawa, Templer, and Arikawa.\n",
    "\n",
    "Let's recall now what was mentioned as the main issue earlier: \"national IQs are **strongly confounded** with the current developmental status of countries\".\n",
    "\n",
    "Kanazawa, Templer, and Arikawa each check correlations to a number of factors, but they leave out many important confounders. \n",
    "\n",
    "<h3> 1. Data Source and Loading <a name=\"datasets\"></a></h3>\n",
    "\n",
    "Lynn and Vanhanen (2006) estimates of National IQ (excluding Equatorial Guinea and Taiwan)\n",
    "\n",
    "Developmental data \"from websites of the United Nations (UN), and World Health Organization (WHO)\" as well as data from UNICEF, UNESCO, International Telecommunication Union, World Development Index, and the Paleoclimate Modelling Intercomparison Project.\n",
    "\n",
    "We'll be starting out with all of the correlations between variables pre-computed to save time.\n",
    "\n",
    "Let's load those in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, '.652', '.776', '-.767', '-.851', '.593', '.717', '.690', '-.838', '-.792', '-.798', '.694', '.753', '.683', '-.617', '.217', '.599', '.345']\n",
      "['.652', 1, '.691', '-.785', '.737', '-.635', '.692', '.875', '-.804', '.930', '.829', '-.695', '.937', '.878', '-.567', '.202', '-.074', '.075']\n",
      "['.776', '.691', 1, '-.785', '.737', '-.635', '.692', '.875', '-.804', '.930', '.829', '-.695', '.937', '.878', '-.567', '.202', '-.074', '.075']\n",
      "['-.767', '-.520', '-.785', 1, '.737', '-.635', '.692', '.875', '-.804', '.930', '.829', '-.695', '.937', '.878', '-.567', '.202', '-.074', '.075']\n",
      "['-.851', '-.650', '-.868', '.737', 1, '-.635', '.692', '.875', '-.804', '.930', '.829', '-.695', '.937', '.878', '-.567', '.202', '-.074', '.075']\n",
      "['.593', '.643', '.701', '-.560', '-.635', 1, '.692', '.875', '-.804', '.930', '.829', '-.695', '.937', '.878', '-.567', '.202', '-.074', '.075']\n",
      "['.717', '.567', '.829', '-.818', '-.768', '.692', 1, '.875', '-.804', '.930', '.829', '-.695', '.937', '.878', '-.567', '.202', '-.074', '.075']\n",
      "['.690', '.524', '.792', '-.734', '-.732', '.682', '.875', 1, '-.804', '.930', '.829', '-.695', '.937', '.878', '-.567', '.202', '-.074', '.075']\n",
      "['-.838', '-.514', '-.852', '.788', '.844', '-.620', '-.844', '-.804', 1, '.930', '.829', '-.695', '.937', '.878', '-.567', '.202', '-.074', '.075']\n",
      "['-.792', '-.589', '-.857', '.761', '.853', '-.628', '-.825', '-.732', '.930', 1, '.829', '-.695', '.937', '.878', '-.567', '.202', '-.074', '.075']\n",
      "['-.798', '-.421', '-.785', '.726', '.760', '-.573', '-.763', '-.695', '.926', '.829', 1, '-.695', '.937', '.878', '-.567', '.202', '-.074', '.075']\n",
      "['.694', '.534', '.755', '-.702', '-.709', '.654', '.751', '.779', '-.716', '-.700', '-.695', 1, '.937', '.878', '-.567', '.202', '-.074', '.075']\n",
      "['.753', '.623', '.805', '-.744', '-.771', '.682', '.770', '.777', '-.760', '-.753', '-.710', '.937', 1, '.878', '-.567', '.202', '-.074', '.075']\n",
      "['.683', '.680', '.810', '-.707', '-.757', '.695', '.800', '.760', '-.703', '-.726', '-.629', '.874', '.878', 1, '-.567', '.202', '-.074', '.075']\n",
      "['-.617', '-.639', '-.726', '.566', '.696', '-.481', '-.499', '-.500', '.531', '.541', '.460', '-.504', '-.623', '-.567', 1, '.202', '-.074', '.075']\n",
      "['.217', '.041', '.110', '-.062', '.082', '-.138', '.161', '.117', '-.184', '-.187', '-.191', '.043', '.017', '.066', '.202', 1, '-.074', '.075']\n",
      "['.599', '.554', '.764', '-.573', '-.695', '.510', '.616', '.553', '-.609', '-.610', '-.531', '.566', '.660', '.650', '-.869', '-.074', 1, '.075']\n",
      "['.345', '.154', '.218', '-.160', '-.238', '-.043', '.275', '.185', '-.304', '-.305', '-.308', '.109', '.081', '.139', '.064', '.945', '.075', 1]\n"
     ]
    }
   ],
   "source": [
    "nat_iq = {}\n",
    "nat_iq_wout_ssa = {}\n",
    "with open(\"correlations_data.txt\", \"r\") as f:\n",
    "    data = f.read().split(\"\\n\")\n",
    "    for i in range(0,len(data)-1, 2):\n",
    "        var = data[i]\n",
    "        var_vals = data[i+1].split(\" \")\n",
    "        \n",
    "        nat_iq[var] = var_vals[1:]\n",
    "        nat_iq_wout_ssa[var] = [var_vals[0]] + var_vals[2:]\n",
    "\n",
    "nat_iq_mat = [[1] + [nat_iq[x][0] for x in nat_iq]]\n",
    "for i,x in enumerate(nat_iq):\n",
    "    li = nat_iq[x] + [1]\n",
    "    for j, y in enumerate(nat_iq):\n",
    "        if j <= i:\n",
    "            continue\n",
    "        li.append(nat_iq[y][-1])\n",
    "    nat_iq_mat.append(li)\n",
    "for l in nat_iq_mat:\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 2. Understanding and Applying PCA <a name=\"pca\"></a></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.90373809e+00 1.24761000e+00 4.47201081e-01 4.04868320e-01\n",
      " 2.52759192e-01 8.52327388e-02 7.05000754e-02 1.65751559e-02\n",
      " 9.17423992e-03 5.31801967e-03 4.26059657e-03 3.68570779e-03\n",
      " 1.41675412e-03 1.00940638e-03 6.27703671e-04 1.96754467e-04\n",
      " 7.76308060e-06 5.81910149e-33]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(svd_solver='full')\n",
    "pca.fit(nat_iq_mat)\n",
    "\n",
    "# For Scree Plot (fig 1) and Table 2\n",
    "print(pca.explained_variance_)\n",
    "# My results are different than their's in scale somewhat - I need to investigate a little.\n",
    "\n",
    "# How do Fig 2 w/out data? Is Fig 2 necessary?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Evaluation <a name=\"Evaluation\"></a> </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Conclusion <a name=\"Conclusion\"></a> </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be careful about confounders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Sources: <a name=\"Sources\"></a></h2>\n",
    "\n",
    "https://en.wikipedia.org/wiki/SAT#History (Introduction Material)\n",
    "\n",
    "https://en.wikipedia.org/wiki/Intelligence_quotient#Precursors_to_IQ_testing (Introduction Material)\n",
    "\n",
    "\n",
    "<h3> Evolutionary Theory Sources </h3>\n",
    "\n",
    "https://lesacreduprintemps19.files.wordpress.com/2012/11/lynn-race-differences-in-intelligence.pdf (Evolutionary theory which claims that temperature and demanding climates motivated development of higher intelligence) Lynn, 2006\n",
    "\n",
    "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.372.6475&rep=rep1&type=pdf (Evolutionary theory that claims that new environmental challenges motivated development of higher intelligence) Kanazawa, 2004\n",
    "\n",
    "https://lesacreduprintemps19.files.wordpress.com/2012/11/jp-rushton-race-evolution-behavior-unabridged-1997-edition.pdf (Evolutionary theory about reproductive strategies being related to intelligence) Rushton, 2000\n",
    "\n",
    "<h3> Papers that we Aim to Debunk </h3>\n",
    "\n",
    "https://personal.lse.ac.uk/kanazawa/pdfs/I2008.pdf Kanazawa 2008 concerning Lynn 2006, Kanazawa 2004\n",
    "\n",
    "https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.174.945&rep=rep1&type=pdf Templer and Arikawa 2006 concerning Lynn 2006\n",
    "\n",
    "https://sci-hubtw.hkvisa.net/10.1016/j.paid.2008.05.010 Templer 2008 concerning Rush 2000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
